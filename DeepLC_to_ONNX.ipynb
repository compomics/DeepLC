{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-01T07:39:02.198926700Z",
     "start_time": "2025-04-01T07:38:51.487284300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Pycharm_envs\\DeepLC_ONNX\\Lib\\site-packages\\tf2onnx\\tf_loader.py:68: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Pycharm_envs\\DeepLC_ONNX\\Lib\\site-packages\\tf2onnx\\tf_loader.py:72: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "from deeplc import DeepLC\n",
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "['D:\\\\OneDrive - UGent\\\\Python Codes\\\\3Projects\\\\DeepLC_ONNX\\\\deeplc\\\\mods/full_hc_PXD005573_pub_1fd8363d9af9dcad3be7553c39396960.keras']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlc = DeepLC()\n",
    "keras_model = dlc.model\n",
    "keras_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-01T07:39:02.208841300Z",
     "start_time": "2025-04-01T07:39:02.199926700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Dimension value must be integer or None or have an __index__ method, got value '(None, 60, 6)' with type '<class 'tuple'>'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m model = tf.keras.models.load_model(keras_model[\u001B[32m0\u001B[39m])\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m spec = \u001B[43mtf\u001B[49m\u001B[43m.\u001B[49m\u001B[43mTensorSpec\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43minput_shape\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[38;5;66;03m# change the spec to a list of tf.TensorSpec\u001B[39;00m\n\u001B[32m      4\u001B[39m \u001B[38;5;28mtype\u001B[39m(spec[\u001B[32m0\u001B[39m])\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Pycharm_envs\\DeepLC_ONNX\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor.py:865\u001B[39m, in \u001B[36mDenseSpec.__init__\u001B[39m\u001B[34m(self, shape, dtype, name)\u001B[39m\n\u001B[32m    853\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, shape, dtype=dtypes.float32, name=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m    854\u001B[39m \u001B[38;5;250m  \u001B[39m\u001B[33;03m\"\"\"Creates a TensorSpec.\u001B[39;00m\n\u001B[32m    855\u001B[39m \n\u001B[32m    856\u001B[39m \u001B[33;03m  Args:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    863\u001B[39m \u001B[33;03m      not convertible to a `tf.DType`.\u001B[39;00m\n\u001B[32m    864\u001B[39m \u001B[33;03m  \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m865\u001B[39m   \u001B[38;5;28mself\u001B[39m._shape = \u001B[43mtensor_shape\u001B[49m\u001B[43m.\u001B[49m\u001B[43mTensorShape\u001B[49m\u001B[43m(\u001B[49m\u001B[43mshape\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    866\u001B[39m   \u001B[38;5;28mself\u001B[39m._dtype = dtypes.as_dtype(dtype)\n\u001B[32m    867\u001B[39m   \u001B[38;5;28mself\u001B[39m._name = name\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Pycharm_envs\\DeepLC_ONNX\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:830\u001B[39m, in \u001B[36mTensorShape.__init__\u001B[39m\u001B[34m(self, dims)\u001B[39m\n\u001B[32m    821\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Creates a new TensorShape with the given dimensions.\u001B[39;00m\n\u001B[32m    822\u001B[39m \n\u001B[32m    823\u001B[39m \u001B[33;03mArgs:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    827\u001B[39m \u001B[33;03m  TypeError: If dims cannot be converted to a list of dimensions.\u001B[39;00m\n\u001B[32m    828\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    829\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(dims, (\u001B[38;5;28mtuple\u001B[39m, \u001B[38;5;28mlist\u001B[39m)):  \u001B[38;5;66;03m# Most common case.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m830\u001B[39m   \u001B[38;5;28mself\u001B[39m._dims = \u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mas_dimension\u001B[49m\u001B[43m(\u001B[49m\u001B[43md\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43md\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdims\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    831\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m dims \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    832\u001B[39m   \u001B[38;5;28mself\u001B[39m._dims = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Pycharm_envs\\DeepLC_ONNX\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:830\u001B[39m, in \u001B[36m<genexpr>\u001B[39m\u001B[34m(.0)\u001B[39m\n\u001B[32m    821\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Creates a new TensorShape with the given dimensions.\u001B[39;00m\n\u001B[32m    822\u001B[39m \n\u001B[32m    823\u001B[39m \u001B[33;03mArgs:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    827\u001B[39m \u001B[33;03m  TypeError: If dims cannot be converted to a list of dimensions.\u001B[39;00m\n\u001B[32m    828\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    829\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(dims, (\u001B[38;5;28mtuple\u001B[39m, \u001B[38;5;28mlist\u001B[39m)):  \u001B[38;5;66;03m# Most common case.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m830\u001B[39m   \u001B[38;5;28mself\u001B[39m._dims = \u001B[38;5;28mtuple\u001B[39m(\u001B[43mas_dimension\u001B[49m\u001B[43m(\u001B[49m\u001B[43md\u001B[49m\u001B[43m)\u001B[49m.value \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m dims)\n\u001B[32m    831\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m dims \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    832\u001B[39m   \u001B[38;5;28mself\u001B[39m._dims = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Pycharm_envs\\DeepLC_ONNX\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:744\u001B[39m, in \u001B[36mas_dimension\u001B[39m\u001B[34m(value)\u001B[39m\n\u001B[32m    742\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m value\n\u001B[32m    743\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m744\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDimension\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Pycharm_envs\\DeepLC_ONNX\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:220\u001B[39m, in \u001B[36mDimension.__init__\u001B[39m\u001B[34m(self, value)\u001B[39m\n\u001B[32m    218\u001B[39m   \u001B[38;5;28mself\u001B[39m._value = \u001B[38;5;28mint\u001B[39m(value.\u001B[34m__index__\u001B[39m())\n\u001B[32m    219\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m220\u001B[39m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[32m    221\u001B[39m       \u001B[33m\"\u001B[39m\u001B[33mDimension value must be integer or None or have \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    222\u001B[39m       \u001B[33m\"\u001B[39m\u001B[33man __index__ method, got value \u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{0!r}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m with type \u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{1!r}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m\"\u001B[39m.format(\n\u001B[32m    223\u001B[39m           value, \u001B[38;5;28mtype\u001B[39m(value))) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    224\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._value < \u001B[32m0\u001B[39m:\n\u001B[32m    225\u001B[39m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mDimension \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[33m must be >= 0\u001B[39m\u001B[33m\"\u001B[39m % \u001B[38;5;28mself\u001B[39m._value)\n",
      "\u001B[31mTypeError\u001B[39m: Dimension value must be integer or None or have an __index__ method, got value '(None, 60, 6)' with type '<class 'tuple'>'"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(keras_model[0])\n",
    "spec = tf.TensorSpec(model.input_shape)\n",
    "# change the spec to a list of tf.TensorSpec\n",
    "type(spec[0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-01T07:42:52.428297900Z",
     "start_time": "2025-04-01T07:42:52.220520Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "input_signature must be a possibly nested sequence of TensorSpec objects, got invalid args [None, 60, 6, None, 30, 6, None, 55, None, 60, 20] with types [<class 'NoneType'>, <class 'int'>, <class 'int'>, <class 'NoneType'>, <class 'int'>, <class 'int'>, <class 'NoneType'>, <class 'int'>, <class 'NoneType'>, <class 'int'>, <class 'int'>].",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      1\u001B[39m onnx_model_path = \u001B[33m\"\u001B[39m\u001B[33mdeeplc.onnx\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;66;03m# spec = [\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[38;5;66;03m#     tf.TensorSpec([None, 60, 6], tf.float32, name=\"input_1\"),\u001B[39;00m\n\u001B[32m      4\u001B[39m \u001B[38;5;66;03m#     tf.TensorSpec([None, 30, 6], tf.float32, name=\"input_2\"),\u001B[39;00m\n\u001B[32m      5\u001B[39m \u001B[38;5;66;03m#     tf.TensorSpec([None, 55], tf.float32, name=\"input_3\"),\u001B[39;00m\n\u001B[32m      6\u001B[39m \u001B[38;5;66;03m#     tf.TensorSpec([None, 60, 20], tf.float32, name=\"input_4\"),\u001B[39;00m\n\u001B[32m      7\u001B[39m \u001B[38;5;66;03m# ]\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m onnx_model, _ = \u001B[43mtf2onnx\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_keras\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_signature\u001B[49m\u001B[43m=\u001B[49m\u001B[43mspec\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopset\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m13\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43monnx_model_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Pycharm_envs\\DeepLC_ONNX\\Lib\\site-packages\\tf2onnx\\convert.py:446\u001B[39m, in \u001B[36mfrom_keras\u001B[39m\u001B[34m(model, input_signature, opset, custom_ops, custom_op_handlers, custom_rewriter, inputs_as_nchw, outputs_as_nchw, extra_opset, shape_override, target, large_model, output_path, optimizers)\u001B[39m\n\u001B[32m    443\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtensorflow\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpython\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mkeras\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msaving\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m saving_utils \u001B[38;5;28;01mas\u001B[39;00m _saving_utils \u001B[38;5;66;03m# pylint: disable=import-outside-toplevel\u001B[39;00m\n\u001B[32m    445\u001B[39m \u001B[38;5;66;03m# let tensorflow do the checking if model is a valid model\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m446\u001B[39m function = \u001B[43m_saving_utils\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrace_model_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_signature\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    447\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    448\u001B[39m     concrete_func = function.get_concrete_function()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Pycharm_envs\\DeepLC_ONNX\\Lib\\site-packages\\tensorflow\\python\\keras\\saving\\saving_utils.py:120\u001B[39m, in \u001B[36mtrace_model_call\u001B[39m\u001B[34m(model, input_signature)\u001B[39m\n\u001B[32m    117\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m input_signature \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    118\u001B[39m   raise_model_input_error(model)\n\u001B[32m--> \u001B[39m\u001B[32m120\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;129;43m@def_function\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_signature\u001B[49m\u001B[43m=\u001B[49m\u001B[43minput_signature\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    121\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mdef\u001B[39;49;00m\u001B[38;5;250;43m \u001B[39;49m\u001B[34;43m_wrapped_model\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    122\u001B[39m \u001B[38;5;250;43m  \u001B[39;49m\u001B[33;43;03m\"\"\"A concrete tf.function that wraps the model's call function.\"\"\"\u001B[39;49;00m\n\u001B[32m    123\u001B[39m \u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# When given a single input, Keras models will call the model on the tensor\u001B[39;49;00m\n\u001B[32m    124\u001B[39m \u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# rather than a list consisting of the single tensor.\u001B[39;49;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Pycharm_envs\\DeepLC_ONNX\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:1658\u001B[39m, in \u001B[36mfunction.<locals>.decorated\u001B[39m\u001B[34m(inner_function)\u001B[39m\n\u001B[32m   1653\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m:\n\u001B[32m   1654\u001B[39m   name = \u001B[33m\"\u001B[39m\u001B[33mfunction\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1655\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m tf_decorator.make_decorator(\n\u001B[32m   1656\u001B[39m     inner_function,\n\u001B[32m   1657\u001B[39m     decorator_name=\u001B[33m\"\u001B[39m\u001B[33mtf.function\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m-> \u001B[39m\u001B[32m1658\u001B[39m     decorator_func=\u001B[43mFunction\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1659\u001B[39m \u001B[43m        \u001B[49m\u001B[43minner_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1660\u001B[39m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1661\u001B[39m \u001B[43m        \u001B[49m\u001B[43minput_signature\u001B[49m\u001B[43m=\u001B[49m\u001B[43minput_signature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1662\u001B[39m \u001B[43m        \u001B[49m\u001B[43mautograph\u001B[49m\u001B[43m=\u001B[49m\u001B[43mautograph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1663\u001B[39m \u001B[43m        \u001B[49m\u001B[43mexperimental_autograph_options\u001B[49m\u001B[43m=\u001B[49m\u001B[43mexperimental_autograph_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1664\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreduce_retracing\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreduce_retracing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1665\u001B[39m \n\u001B[32m   1666\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# TODO(b/171825496): Update once `experimental_compile` is removed\u001B[39;49;00m\n\u001B[32m   1667\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# entirely in favor of 'jit_compile'.\u001B[39;49;00m\n\u001B[32m   1668\u001B[39m \u001B[43m        \u001B[49m\u001B[43mjit_compile\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdeprecation\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdeprecated_argument_lookup\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1669\u001B[39m \u001B[43m            \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mjit_compile\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1670\u001B[39m \u001B[43m            \u001B[49m\u001B[43mjit_compile\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1671\u001B[39m \u001B[43m            \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mexperimental_compile\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1672\u001B[39m \u001B[43m            \u001B[49m\u001B[43mexperimental_compile\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1673\u001B[39m \u001B[43m        \u001B[49m\u001B[43mexperimental_implements\u001B[49m\u001B[43m=\u001B[49m\u001B[43mexperimental_implements\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1674\u001B[39m \u001B[43m        \u001B[49m\u001B[43mexperimental_attributes\u001B[49m\u001B[43m=\u001B[49m\u001B[43mexperimental_attributes\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Pycharm_envs\\DeepLC_ONNX\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:492\u001B[39m, in \u001B[36mFunction.__init__\u001B[39m\u001B[34m(self, python_function, name, input_signature, autograph, jit_compile, reduce_retracing, experimental_implements, experimental_autograph_options, experimental_attributes)\u001B[39m\n\u001B[32m    489\u001B[39m \u001B[38;5;28mself\u001B[39m._lock = threading.RLock()\n\u001B[32m    490\u001B[39m \u001B[38;5;28mself\u001B[39m._python_function = python_function\n\u001B[32m    491\u001B[39m \u001B[38;5;28mself\u001B[39m._function_type, \u001B[38;5;28mself\u001B[39m._default_values = (\n\u001B[32m--> \u001B[39m\u001B[32m492\u001B[39m     \u001B[43mfunction_type_utils\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmake_function_type\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpython_function\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_signature\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    493\u001B[39m )\n\u001B[32m    494\u001B[39m \u001B[38;5;28mself\u001B[39m._function_cache = function_cache.FunctionCache()\n\u001B[32m    495\u001B[39m \u001B[38;5;28mself\u001B[39m._function_captures = capture_container.FunctionCaptures()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Pycharm_envs\\DeepLC_ONNX\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\function_type_utils.py:344\u001B[39m, in \u001B[36mmake_function_type\u001B[39m\u001B[34m(python_function, input_signature)\u001B[39m\n\u001B[32m    342\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mmake_function_type\u001B[39m(python_function, input_signature):\n\u001B[32m    343\u001B[39m \u001B[38;5;250m  \u001B[39m\u001B[33;03m\"\"\"Generates a FunctionType for python_function.\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m344\u001B[39m   \u001B[43m_validate_signature\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_signature\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    346\u001B[39m   function_type = function_type_lib.FunctionType.from_callable(\n\u001B[32m    347\u001B[39m       python_function\n\u001B[32m    348\u001B[39m   )\n\u001B[32m    349\u001B[39m   default_values = function_type_lib.FunctionType.get_default_values(\n\u001B[32m    350\u001B[39m       python_function\n\u001B[32m    351\u001B[39m   )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Pycharm_envs\\DeepLC_ONNX\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\function_type_utils.py:481\u001B[39m, in \u001B[36m_validate_signature\u001B[39m\u001B[34m(signature)\u001B[39m\n\u001B[32m    472\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28many\u001B[39m(\n\u001B[32m    473\u001B[39m     \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arg, tensor.TensorSpec)\n\u001B[32m    474\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m arg \u001B[38;5;129;01min\u001B[39;00m nest.flatten(signature, expand_composites=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m    475\u001B[39m ):\n\u001B[32m    476\u001B[39m   bad_args = [\n\u001B[32m    477\u001B[39m       arg\n\u001B[32m    478\u001B[39m       \u001B[38;5;28;01mfor\u001B[39;00m arg \u001B[38;5;129;01min\u001B[39;00m nest.flatten(signature, expand_composites=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m    479\u001B[39m       \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arg, tensor.TensorSpec)\n\u001B[32m    480\u001B[39m   ]\n\u001B[32m--> \u001B[39m\u001B[32m481\u001B[39m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[32m    482\u001B[39m       \u001B[33m\"\u001B[39m\u001B[33minput_signature must be a possibly nested sequence of \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    483\u001B[39m       \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mTensorSpec objects, got invalid args \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbad_args\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m with \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    484\u001B[39m       \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mtypes \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(six.moves.map(\u001B[38;5;28mtype\u001B[39m,\u001B[38;5;250m \u001B[39mbad_args))\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    485\u001B[39m   )\n",
      "\u001B[31mTypeError\u001B[39m: input_signature must be a possibly nested sequence of TensorSpec objects, got invalid args [None, 60, 6, None, 30, 6, None, 55, None, 60, 20] with types [<class 'NoneType'>, <class 'int'>, <class 'int'>, <class 'NoneType'>, <class 'int'>, <class 'int'>, <class 'NoneType'>, <class 'int'>, <class 'NoneType'>, <class 'int'>, <class 'int'>]."
     ]
    }
   ],
   "source": [
    "onnx_model_path = \"deeplc.onnx\"\n",
    "# spec = [\n",
    "#     tf.TensorSpec([None, 60, 6], tf.float32, name=\"input_1\"),\n",
    "#     tf.TensorSpec([None, 30, 6], tf.float32, name=\"input_2\"),\n",
    "#     tf.TensorSpec([None, 55], tf.float32, name=\"input_3\"),\n",
    "#     tf.TensorSpec([None, 60, 20], tf.float32, name=\"input_4\"),\n",
    "# ]\n",
    "\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=13, output_path=onnx_model_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-01T07:41:05.129698800Z",
     "start_time": "2025-04-01T07:41:04.955572900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from onnx2torch import convert\n",
    "import torch\n",
    "\n",
    "onnx_model = onnx.load(onnx_model_path)\n",
    "pytorch_onnx_model = convert(onnx_model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-28T09:19:47.116485100Z",
     "start_time": "2025-03-28T09:19:40.387363100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Model Output: tensor([[49.3896]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_tensors = (\n",
    "    torch.randn(1, 60, 6),  # Input 1\n",
    "    torch.randn(1, 30, 6),  # Input 2\n",
    "    torch.randn(1, 55),     # Input 3\n",
    "    torch.randn(1, 60, 20)  # Input 4\n",
    ")\n",
    "\n",
    "# Run PyTorch model\n",
    "output = pytorch_onnx_model(*input_tensors)\n",
    "print(\"PyTorch Model Output:\", output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-28T09:19:47.139171500Z",
     "start_time": "2025-03-28T09:19:47.116485100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX Model Output: [array([[-18.030432],\n",
      "       [ 43.959698],\n",
      "       [ 58.209183]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from deeplc import DeepLC\n",
    "from psm_utils.psm import PSM\n",
    "from psm_utils.psm_list import PSMList\n",
    "from psm_utils.io.peptide_record import peprec_to_proforma\n",
    "\n",
    "# Initialize DeepLC\n",
    "dlc = DeepLC()\n",
    "\n",
    "# Example peptide sequences with modifications\n",
    "peptides = [\"AAGPSLSHTSGGTQSK\", \"AAINQKLIETGER\", \"AANDAGYFNDEMAPIEVKTK\"]\n",
    "modifications = [\"\", \"6|Acetyl\", \"12|Oxidation|18|Acetyl\"]\n",
    "identifiers = [\"peptide1\", \"peptide2\", \"peptide3\"]\n",
    "\n",
    "# Convert peptide + modifications into ProForma notation\n",
    "list_of_psms = [\n",
    "    PSM(peptidoform=peprec_to_proforma(seq, mod), spectrum_id=ident)\n",
    "    for seq, mod, ident in zip(peptides, modifications, identifiers)\n",
    "]\n",
    "\n",
    "# Convert to a PSMList\n",
    "psm_list = PSMList(psm_list=list_of_psms)\n",
    "\n",
    "# Extract numerical features using DeepLC\n",
    "feature_dict = dlc.do_f_extraction_psm_list(psm_list)\n",
    "\n",
    "# Ensure extracted features match ONNX expected shape\n",
    "input_1 = np.stack(list(feature_dict[\"matrix\"].values())).astype(np.float32)  # [batch, 60, 6]\n",
    "input_2 = np.stack(list(feature_dict[\"matrix_sum\"].values())).astype(np.float32)  # [batch, 30, 6]\n",
    "input_3 = np.stack(list(feature_dict[\"matrix_all\"].values())).astype(np.float32)  # [batch, ?] (Fix applied below)\n",
    "input_4 = np.stack(list(feature_dict[\"pos_matrix\"].values())).astype(np.float32)  # [batch, ?] (Fix applied below)\n",
    "\n",
    "# ðŸ”¥ Fix `input_3`: Ensure it has exactly 55 features\n",
    "expected_input_3_dim = 55\n",
    "if input_3.shape[1] != expected_input_3_dim:\n",
    "    padded_input_3 = np.zeros((input_3.shape[0], expected_input_3_dim), dtype=np.float32)\n",
    "    padded_input_3[:, :input_3.shape[1]] = input_3  # Fill with available data\n",
    "    input_3 = padded_input_3\n",
    "\n",
    "# ðŸ”¥ Fix `input_4`: Ensure it is **3D with shape [batch, 60, 20]**\n",
    "expected_input_4_shape = (input_4.shape[0], 60, 20)\n",
    "\n",
    "# ðŸ› ï¸ Ensure input_4 is **at least 2D**\n",
    "if input_4.ndim == 2:\n",
    "    input_4 = np.expand_dims(input_4, axis=-1)  # Convert [batch, X] â†’ [batch, X, 1]\n",
    "\n",
    "# ðŸ› ï¸ Now, reshape or pad to exactly `[batch, 60, 20]`\n",
    "padded_input_4 = np.zeros(expected_input_4_shape, dtype=np.float32)\n",
    "\n",
    "# Find minimum matching dimensions\n",
    "min_dim1 = min(input_4.shape[1], 60)\n",
    "min_dim2 = min(input_4.shape[2], 20)\n",
    "\n",
    "# Fill with available data\n",
    "padded_input_4[:, :min_dim1, :min_dim2] = input_4[:, :min_dim1, :min_dim2]\n",
    "input_4 = padded_input_4  # Replace with corrected array\n",
    "\n",
    "# Load ONNX model\n",
    "onnx_model_path = \"deeplc.onnx\"\n",
    "ort_session = ort.InferenceSession(onnx_model_path)\n",
    "\n",
    "# Prepare inputs for ONNX\n",
    "onnx_inputs = {\n",
    "    \"input_1\": input_1,  # [batch, 60, 6]\n",
    "    \"input_2\": input_2,  # [batch, 30, 6]\n",
    "    \"input_3\": input_3,  # [batch, 55]  âœ… Now correctly sized\n",
    "    \"input_4\": input_4   # [batch, 60, 20]  âœ… Now correctly sized\n",
    "}\n",
    "\n",
    "# Run ONNX model\n",
    "onnx_outputs = ort_session.run(None, onnx_inputs)\n",
    "\n",
    "# Print output predictions\n",
    "print(\"ONNX Model Output:\", onnx_outputs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-24T10:08:00.921188100Z",
     "start_time": "2025-03-24T10:07:59.851947100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-01T09:30:24.101875400Z",
     "start_time": "2025-04-01T09:30:23.013818300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "PSM List Lengths: 33421 3909\n",
      "(3909, 55)\n",
      "Input Shapes: (33421, 60, 6) (33421, 30, 6) (3909, 55) (33421, 60, 20)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from onnx2torch import convert\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import DeepLC and related utilities for feature extraction\n",
    "from deeplc import DeepLC\n",
    "from psm_utils.psm import PSM\n",
    "from psm_utils.psm_list import PSMList\n",
    "from psm_utils.io.peptide_record import peprec_to_proforma\n",
    "import copy\n",
    "\n",
    "# Set device for PyTorch computations\n",
    "device = torch.device(\"cuda\")\n",
    "print(device)\n",
    "\n",
    "csv_file = \"ATLANTIS_SILICA_fixed_mods.csv\"\n",
    "data = pd.read_csv(csv_file, keep_default_na=False)\n",
    "train_data = data[data['set_type'] == 'train']\n",
    "test_data = data[data['set_type'] == 'test']\n",
    "\n",
    "psm_list_train = PSMList(psm_list=[\n",
    "    PSM(peptidoform=peprec_to_proforma(row[\"seq\"], row[\"modifications\"]), spectrum_id=str(idx))\n",
    "    for idx, row in train_data.iterrows()\n",
    "])\n",
    "\n",
    "psm_list_test = PSMList(psm_list=[\n",
    "    PSM(peptidoform=peprec_to_proforma(row[\"seq\"], row[\"modifications\"]), spectrum_id=str(idx))\n",
    "    for idx, row in test_data.iterrows()\n",
    "])\n",
    "print(\"PSM List Lengths:\", len(psm_list_train), len(psm_list_test))\n",
    "dlc = DeepLC()\n",
    "feature_dict_train = dlc.do_f_extraction_psm_list(psm_list_train)\n",
    "feature_dict_test = dlc.do_f_extraction_psm_list(psm_list_test)\n",
    "\n",
    "input_1_train = np.stack(list(feature_dict_train[\"matrix\"].values())).astype(np.float32)\n",
    "input_2_train = np.stack(list(feature_dict_train[\"matrix_sum\"].values())).astype(np.float32)\n",
    "input_3_train = np.stack(list(feature_dict_train[\"matrix_all\"].values())).astype(np.float32)\n",
    "input_4_train = np.stack(list(feature_dict_train[\"pos_matrix\"].values())).astype(np.float32)\n",
    "\n",
    "input_1_test = np.stack(list(feature_dict_test[\"matrix\"].values())).astype(np.float32)\n",
    "input_2_test = np.stack(list(feature_dict_test[\"matrix_sum\"].values())).astype(np.float32)\n",
    "input_3_test = np.stack(list(feature_dict_test[\"matrix_all\"].values())).astype(np.float32)\n",
    "input_4_test = np.stack(list(feature_dict_test[\"pos_matrix\"].values())).astype(np.float32)\n",
    "\n",
    "\n",
    "# Ensure input_3 is a 2D tensor with shape [batch, 55].\n",
    "expected_input_3_dim = 55\n",
    "if input_3_train.shape[1] != expected_input_3_dim:\n",
    "    padded_input_3_train = np.zeros((input_3_train.shape[0], expected_input_3_dim), dtype=np.float32)\n",
    "    padded_input_3_train[:, :input_3_train.shape[1]] = input_3_train\n",
    "    input_3_train = padded_input_3_train\n",
    "\n",
    "if input_3_test.shape[1] != 55:\n",
    "    padded_input_3_test = np.zeros((input_3_test.shape[0], 55), dtype=np.float32)\n",
    "    padded_input_3_test[:, :input_3_test.shape[1]] = input_3_test\n",
    "    input_3_test = padded_input_3_test\n",
    "    print(padded_input_3_test.shape)\n",
    "\n",
    "# Ensure input_4 is a 3D tensor with shape [batch, 60, 20].\n",
    "expected_input_4_train_shape = (input_4_train.shape[0], 60, 20)\n",
    "if input_4_train.ndim == 2:\n",
    "    input_4_train = np.expand_dims(input_4_train, axis=-1)\n",
    "padded_input_4_train = np.zeros(expected_input_4_train_shape, dtype=np.float32)\n",
    "min_dim1 = min(input_4_train.shape[1], 60)\n",
    "min_dim2 = min(input_4_train.shape[2], 20)\n",
    "padded_input_4_train[:, :min_dim1, :min_dim2] = input_4_train[:, :min_dim1, :min_dim2]\n",
    "input_4_train = padded_input_4_train\n",
    "\n",
    "expected_input_4_test_shape = (input_4_test.shape[0], 60, 20)\n",
    "if input_4_test.ndim == 2:\n",
    "    input_4_test = np.expand_dims(input_4_test, axis=-1)\n",
    "padded_input_4_test = np.zeros(expected_input_4_test_shape, dtype=np.float32)\n",
    "min_dim1 = min(input_4_test.shape[1], 60)\n",
    "min_dim2 = min(input_4_test.shape[2], 20)\n",
    "padded_input_4_test[:, :min_dim1, :min_dim2] = input_4_test[:, :min_dim1, :min_dim2]\n",
    "input_4_test = padded_input_4_test\n",
    "\n",
    "print(\"Input Shapes:\", input_1_train.shape, input_2_train.shape, input_3_test.shape, input_4_train.shape)\n",
    "\n",
    "y_train = train_data[\"tr\"].values.astype(np.float32)\n",
    "y_test = test_data[\"tr\"].values.astype(np.float32)\n",
    "\n",
    "\n",
    "class DeepLCDataset(Dataset):\n",
    "    def __init__(self, in1, in2, in3, in4, targets):\n",
    "        self.in1 = in1\n",
    "        self.in2 = in2\n",
    "        self.in3 = in3\n",
    "        self.in4 = in4\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.in1.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.in1[idx]),\n",
    "            torch.tensor(self.in2[idx]),\n",
    "            torch.tensor(self.in3[idx]),\n",
    "            torch.tensor(self.in4[idx]),\n",
    "            torch.tensor(self.targets[idx])\n",
    "        )\n",
    "train_dataset = DeepLCDataset(input_1_train, input_2_train, input_3_train, input_4_train, y_train)\n",
    "test_dataset = DeepLCDataset(input_1_test, input_2_test, input_3_test, input_4_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-01T09:30:44.013447400Z",
     "start_time": "2025-04-01T09:30:36.817505100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss Before Transfer Learning: 1993.7402\n",
      "Epoch 1/10, Loss: 87.4707\n",
      "Epoch 2/10, Loss: 6.1276\n",
      "Epoch 3/10, Loss: 4.3014\n",
      "Epoch 4/10, Loss: 3.3294\n",
      "Epoch 5/10, Loss: 2.6490\n",
      "Epoch 6/10, Loss: 2.2131\n",
      "Epoch 7/10, Loss: 1.8851\n",
      "Epoch 8/10, Loss: 1.6242\n",
      "Epoch 9/10, Loss: 1.4299\n",
      "Epoch 10/10, Loss: 1.2613\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "onnx_model_path = \"deeplc.onnx\"\n",
    "onnx_model = onnx.load(onnx_model_path)\n",
    "pretrained_model = convert(onnx_model)  # Convert ONNX model to PyTorch\n",
    "fine_tuned_model = copy.deepcopy(pretrained_model)  # Create a copy for fine-tuning\n",
    "pretrained_model.to(device)\n",
    "fine_tuned_model.to(device)\n",
    "\n",
    "# Note the optimizer now updates fine_tuned_model's parameters.\n",
    "optimizer = optim.Adam(fine_tuned_model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.MSELoss()\n",
    "num_epochs = 10\n",
    "\n",
    "# Evaluation before transfer learning (using pretrained_model)\n",
    "pretrained_model.eval()\n",
    "initial_test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        in1, in2, in3, in4, targets = batch\n",
    "        in1 = in1.to(device)\n",
    "        in2 = in2.to(device)\n",
    "        in3 = in3.to(device)\n",
    "        in4 = in4.to(device)\n",
    "        targets = targets.to(device).view(-1, 1)\n",
    "        outputs = pretrained_model(in1, in2, in3, in4)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        initial_test_loss += loss.item()\n",
    "initial_test_loss /= len(test_loader)\n",
    "print(f\"Test Loss Before Transfer Learning: {initial_test_loss:.4f}\")\n",
    "\n",
    "# Fine-tuning the fine_tuned_model\n",
    "fine_tuned_model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        in1, in2, in3, in4, targets = batch\n",
    "        in1 = in1.to(device)\n",
    "        in2 = in2.to(device)\n",
    "        in3 = in3.to(device)\n",
    "        in4 = in4.to(device)\n",
    "        targets = targets.to(device).view(-1, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = fine_tuned_model(in1, in2, in3, in4)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-01T09:31:55.259515100Z",
     "start_time": "2025-04-01T09:30:48.124048200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.2854\n"
     ]
    }
   ],
   "source": [
    "fine_tuned_model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        in1, in2, in3, in4, targets = batch\n",
    "        in1 = in1.to(device)\n",
    "        in2 = in2.to(device)\n",
    "        in3 = in3.to(device)\n",
    "        in4 = in4.to(device)\n",
    "        targets = targets.to(device).view(-1, 1)\n",
    "        outputs = fine_tuned_model(in1, in2, in3, in4)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        test_loss += loss.item()\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-01T09:31:57.968532600Z",
     "start_time": "2025-04-01T09:31:57.291520300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1993.7402\n"
     ]
    }
   ],
   "source": [
    "pretrained_model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        in1, in2, in3, in4, targets = batch\n",
    "        in1 = in1.to(device)\n",
    "        in2 = in2.to(device)\n",
    "        in3 = in3.to(device)\n",
    "        in4 = in4.to(device)\n",
    "        targets = targets.to(device).view(-1, 1)\n",
    "        outputs = pretrained_model(in1, in2, in3, in4)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        test_loss += loss.item()\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-01T09:31:58.930847700Z",
     "start_time": "2025-04-01T09:31:58.353346Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\OneDrive - UGent\\Python Codes\\3Projects\\DeepLC_ONNX\\deeplc\\deeplc.py:269: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  return \"\"\"\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "DeepLC instance is not yet calibrated.                                        Calibrate before making predictions, or use calibrate=False",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAssertionError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[48]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      7\u001B[39m dlc = DeepLC()\n\u001B[32m      8\u001B[39m \u001B[38;5;66;03m# dlc.calibrate_preds(seq_df=calibration_file)\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m dlc_preds=\u001B[43mdlc\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmake_preds\u001B[49m\u001B[43m(\u001B[49m\u001B[43mseq_df\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpeptide_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcalibrate\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\OneDrive - UGent\\Python Codes\\3Projects\\DeepLC_ONNX\\deeplc\\deeplc.py:759\u001B[39m, in \u001B[36mDeepLC.make_preds\u001B[39m\u001B[34m(self, psm_list, infile, calibrate, seq_df, mod_name)\u001B[39m\n\u001B[32m    756\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m.model, \u001B[38;5;28mlist\u001B[39m):\n\u001B[32m    757\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m m_name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.model:\n\u001B[32m    758\u001B[39m         ret_preds.append(\n\u001B[32m--> \u001B[39m\u001B[32m759\u001B[39m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmake_preds_core\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    760\u001B[39m \u001B[43m                \u001B[49m\u001B[43mX\u001B[49m\u001B[43m=\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    761\u001B[39m \u001B[43m                \u001B[49m\u001B[43mX_sum\u001B[49m\u001B[43m=\u001B[49m\u001B[43mX_sum\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    762\u001B[39m \u001B[43m                \u001B[49m\u001B[43mX_global\u001B[49m\u001B[43m=\u001B[49m\u001B[43mX_global\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    763\u001B[39m \u001B[43m                \u001B[49m\u001B[43mX_hc\u001B[49m\u001B[43m=\u001B[49m\u001B[43mX_hc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    764\u001B[39m \u001B[43m                \u001B[49m\u001B[43mcalibrate\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcalibrate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    765\u001B[39m \u001B[43m                \u001B[49m\u001B[43mmod_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mm_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    766\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    767\u001B[39m         )\n\u001B[32m    768\u001B[39m     ret_preds = np.array([\u001B[38;5;28msum\u001B[39m(a) / \u001B[38;5;28mlen\u001B[39m(a) \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(*ret_preds)])\n\u001B[32m    769\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\OneDrive - UGent\\Python Codes\\3Projects\\DeepLC_ONNX\\deeplc\\deeplc.py:590\u001B[39m, in \u001B[36mDeepLC.make_preds_core\u001B[39m\u001B[34m(self, X, X_sum, X_global, X_hc, psm_list, calibrate, mod_name)\u001B[39m\n\u001B[32m    562\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    563\u001B[39m \u001B[33;03mMake predictions for sequences\u001B[39;00m\n\u001B[32m    564\u001B[39m \u001B[33;03mParameters\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    586\u001B[39m \u001B[33;03m    predictions\u001B[39;00m\n\u001B[32m    587\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    588\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m calibrate:\n\u001B[32m    589\u001B[39m     \u001B[38;5;28;01massert\u001B[39;00m (\n\u001B[32m--> \u001B[39m\u001B[32m590\u001B[39m         \u001B[38;5;28mself\u001B[39m.calibrate_dict\n\u001B[32m    591\u001B[39m     ), \u001B[33m\"\u001B[39m\u001B[33mDeepLC instance is not yet calibrated.\u001B[39m\u001B[38;5;130;01m\\\u001B[39;00m\n\u001B[32m    592\u001B[39m \u001B[33m                                Calibrate before making predictions, or use calibrate=False\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    594\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(X) == \u001B[32m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(psm_list) > \u001B[32m0\u001B[39m:\n\u001B[32m    595\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.verbose:\n",
      "\u001B[31mAssertionError\u001B[39m: DeepLC instance is not yet calibrated.                                        Calibrate before making predictions, or use calibrate=False"
     ]
    }
   ],
   "source": [
    "csv_file = \"ATLANTIS_SILICA_fixed_mods.csv\"\n",
    "data = pd.read_csv(csv_file, keep_default_na=False)\n",
    "\n",
    "peptide_file = data[data['set_type'] == 'test']\n",
    "calibration_file = data[data['set_type'] == 'train']\n",
    "\n",
    "dlc = DeepLC()\n",
    "# dlc.calibrate_preds(seq_df=calibration_file)\n",
    "dlc_preds=dlc.make_preds(seq_df=peptide_file, calibrate=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-01T13:49:10.447532500Z",
     "start_time": "2025-04-01T13:48:53.731180600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_fn(torch.tensor(dlc_preds), torch.tensor(peptide_file['tr'].values)).item()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-01T13:49:10.446535600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "fine_tuned_model.eval()\n",
    "test_loss = 0.0\n",
    "outputss = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        in1, in2, in3, in4, targets = batch\n",
    "        in1 = in1.to(device)\n",
    "        in2 = in2.to(device)\n",
    "        in3 = in3.to(device)\n",
    "        in4 = in4.to(device)\n",
    "        targets = targets.to(device).view(-1, 1)\n",
    "        outputs = fine_tuned_model(in1, in2, in3, in4)\n",
    "        outputss.append(outputs)\n",
    "combined_list = [val.item() for tensor in outputss for val in tensor.cpu().view(-1)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-01T09:46:00.971225300Z",
     "start_time": "2025-04-01T09:46:00.216936900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "2.296053599189575"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(torch.tensor(combined_list), torch.tensor(peptide_file['tr'].values)).item()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-01T09:46:00.975419Z",
     "start_time": "2025-04-01T09:46:00.972222200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-01T09:43:49.502289800Z",
     "start_time": "2025-04-01T09:43:49.487339700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
